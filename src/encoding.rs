//! Text → embedding → hypervector encoding pipeline.
//!
//! Provides the `TextEncoder` trait for pluggable embedding backends,
//! a `SimpleHashEncoder` for offline/testing use, and the `EncodingPipeline`
//! that chains text encoding with codebook projection and HDC algebra.

use std::collections::HashMap;

use chrono::{DateTime, Utc};
use thiserror::Error;

use crate::codebook::Codebook;
use crate::memory::HyperMemory;
use crate::wave::normalize;

/// Errors that can occur during encoding.
#[derive(Debug, Error)]
pub enum EncodingError {
    #[error("empty input text")]
    EmptyInput,
    #[error("dimension mismatch: expected {expected}, got {got}")]
    DimensionMismatch { expected: usize, got: usize },
    #[error("encoding failed: {0}")]
    Other(String),
}

/// Abstraction for text → dense embedding backends.
pub trait TextEncoder: Send + Sync {
    fn embed(&self, text: &str) -> Result<Vec<f32>, EncodingError>;
    fn embedding_dim(&self) -> usize;
}

/// A fast, deterministic hash-based encoder for testing.
/// Tokenizes on whitespace, hashes each token to a vector, then bundles.
pub struct SimpleHashEncoder {
    dim: usize,
    seed: u64,
}

impl SimpleHashEncoder {
    pub fn new(dim: usize, seed: u64) -> Self {
        Self { dim, seed }
    }

    /// Deterministic hash-based vector for a single token.
    fn token_vector(&self, token: &str) -> Vec<f32> {
        let mut v = vec![0.0f32; self.dim];
        // Use a simple hash mixing scheme
        let mut h = self.seed;
        for byte in token.bytes() {
            h = h.wrapping_mul(6364136223846793005).wrapping_add(byte as u64);
        }
        for i in 0..self.dim {
            // Derive per-dimension value from hash
            h = h.wrapping_mul(6364136223846793005).wrapping_add(i as u64);
            // Map to [-1, 1] range
            v[i] = ((h >> 33) as f32 / (u32::MAX as f32)) * 2.0 - 1.0;
        }
        v
    }
}

impl TextEncoder for SimpleHashEncoder {
    fn embed(&self, text: &str) -> Result<Vec<f32>, EncodingError> {
        let tokens: Vec<&str> = text.split_whitespace().collect();
        if tokens.is_empty() {
            return Err(EncodingError::EmptyInput);
        }
        // Bundle all token vectors
        let mut result = vec![0.0f32; self.dim];
        for token in &tokens {
            let tv = self.token_vector(token);
            for (i, val) in tv.iter().enumerate() {
                result[i] += val;
            }
        }
        normalize(&mut result);
        Ok(result)
    }

    fn embedding_dim(&self) -> usize {
        self.dim
    }
}

/// Calls an OpenAI-compatible HTTP embedding API.
pub struct HttpEmbeddingEncoder {
    api_url: String,
    api_key: Option<String>,
    model: String,
    embedding_dim: usize,
}

impl HttpEmbeddingEncoder {
    /// Create a new HTTP embedding encoder.
    ///
    /// `api_url` should be the base URL (e.g. `https://api.openai.com`).
    /// The encoder will POST to `{api_url}/v1/embeddings`.
    pub fn new(api_url: String, api_key: Option<String>, model: String, embedding_dim: usize) -> Self {
        Self { api_url, api_key, model, embedding_dim }
    }

    /// Create an encoder configured for OpenAI's `text-embedding-3-small` (1536 dims).
    pub fn openai_small(api_key: String) -> Self {
        Self::new(
            "https://api.openai.com".to_string(),
            Some(api_key),
            "text-embedding-3-small".to_string(),
            1536,
        )
    }
}

impl TextEncoder for HttpEmbeddingEncoder {
    fn embed(&self, text: &str) -> Result<Vec<f32>, EncodingError> {
        if text.trim().is_empty() {
            return Err(EncodingError::EmptyInput);
        }

        let url = format!("{}/v1/embeddings", self.api_url.trim_end_matches('/'));
        let body = serde_json::json!({
            "input": text,
            "model": &self.model,
        });

        let mut req = ureq::post(&url).set("Content-Type", "application/json");
        if let Some(ref key) = self.api_key {
            req = req.set("Authorization", &format!("Bearer {}", key));
        }

        let resp = req
            .send_json(body)
            .map_err(|e| EncodingError::Other(format!("HTTP request failed: {}", e)))?;

        let json: serde_json::Value = resp
            .into_json()
            .map_err(|e| EncodingError::Other(format!("failed to parse response: {}", e)))?;

        let embedding = json["data"][0]["embedding"]
            .as_array()
            .ok_or_else(|| EncodingError::Other("missing embedding in response".to_string()))?
            .iter()
            .map(|v| v.as_f64().unwrap_or(0.0) as f32)
            .collect::<Vec<f32>>();

        if embedding.len() != self.embedding_dim {
            return Err(EncodingError::DimensionMismatch {
                expected: self.embedding_dim,
                got: embedding.len(),
            });
        }

        Ok(embedding)
    }

    fn embedding_dim(&self) -> usize {
        self.embedding_dim
    }
}

/// Wrapper that caches embeddings to avoid redundant API calls.
pub struct CachedEncoder<E: TextEncoder> {
    inner: E,
    cache: std::sync::RwLock<HashMap<String, Vec<f32>>>,
}

impl<E: TextEncoder> CachedEncoder<E> {
    pub fn new(inner: E) -> Self {
        Self {
            inner,
            cache: std::sync::RwLock::new(HashMap::new()),
        }
    }
}

impl<E: TextEncoder> TextEncoder for CachedEncoder<E> {
    fn embed(&self, text: &str) -> Result<Vec<f32>, EncodingError> {
        let key = text.to_string();
        if let Some(cached) = self.cache.read().unwrap().get(&key) {
            return Ok(cached.clone());
        }
        let result = self.inner.embed(text)?;
        self.cache.write().unwrap().insert(key, result.clone());
        Ok(result)
    }

    fn embedding_dim(&self) -> usize {
        self.inner.embedding_dim()
    }
}

/// Fallback chain: tries primary encoder, falls back on error.
pub struct CompositeEncoder {
    primary: Box<dyn TextEncoder>,
    fallback: Box<dyn TextEncoder>,
}

impl CompositeEncoder {
    pub fn new(primary: Box<dyn TextEncoder>, fallback: Box<dyn TextEncoder>) -> Self {
        Self { primary, fallback }
    }
}

impl TextEncoder for CompositeEncoder {
    fn embed(&self, text: &str) -> Result<Vec<f32>, EncodingError> {
        match self.primary.embed(text) {
            Ok(v) => Ok(v),
            Err(_) => self.fallback.embed(text),
        }
    }

    fn embedding_dim(&self) -> usize {
        self.primary.embedding_dim()
    }
}

/// Full text → hypervector encoding pipeline with HDC algebra.
pub struct EncodingPipeline {
    encoder: Box<dyn TextEncoder>,
    codebook: Codebook,
}

impl EncodingPipeline {
    pub fn new(encoder: Box<dyn TextEncoder>, codebook: Codebook) -> Self {
        assert_eq!(
            encoder.embedding_dim(),
            codebook.input_dim,
            "encoder dim must match codebook input dim"
        );
        Self { encoder, codebook }
    }

    /// Access the codebook.
    pub fn codebook(&self) -> &Codebook {
        &self.codebook
    }

    /// Encode text to a unit-length hypervector (10K dims).
    pub fn encode_text(&self, text: &str) -> Result<Vec<f32>, EncodingError> {
        let embedding = self.encoder.embed(text)?;
        Ok(self.codebook.project(&embedding))
    }

    /// Full pipeline: encode text → create HyperMemory with default wave params.
    pub fn encode_memory(
        &self,
        text: &str,
        _timestamp: DateTime<Utc>,
    ) -> Result<HyperMemory, EncodingError> {
        let hv = self.encode_text(text)?;
        Ok(HyperMemory::new(hv, text.to_string()))
    }

    /// Binding operation ⊗: element-wise multiply.
    pub fn bind(&self, a: &[f32], b: &[f32]) -> Vec<f32> {
        a.iter().zip(b.iter()).map(|(x, y)| x * y).collect()
    }

    /// Bundling operation ⊕: element-wise sum + normalize.
    pub fn bundle(&self, vectors: &[Vec<f32>]) -> Vec<f32> {
        assert!(!vectors.is_empty());
        let dim = vectors[0].len();
        let mut result = vec![0.0f32; dim];
        for v in vectors {
            for (i, val) in v.iter().enumerate() {
                result[i] += val;
            }
        }
        normalize(&mut result);
        result
    }

    /// Permutation operation Π: circular shift of coordinates.
    pub fn permute(&self, v: &[f32], shifts: usize) -> Vec<f32> {
        let n = v.len();
        if n == 0 {
            return vec![];
        }
        let shifts = shifts % n;
        let mut result = vec![0.0f32; n];
        for i in 0..n {
            result[(i + shifts) % n] = v[i];
        }
        result
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::wave::cosine_similarity;

    fn make_pipeline() -> EncodingPipeline {
        let encoder = SimpleHashEncoder::new(384, 42);
        let codebook = Codebook::new(384, 10_000, 42);
        EncodingPipeline::new(Box::new(encoder), codebook)
    }

    #[test]
    fn hash_encoder_consistent() {
        let enc = SimpleHashEncoder::new(128, 42);
        let v1 = enc.embed("hello world").unwrap();
        let v2 = enc.embed("hello world").unwrap();
        assert_eq!(v1, v2);
    }

    #[test]
    fn hash_encoder_different_texts_differ() {
        let enc = SimpleHashEncoder::new(128, 42);
        let v1 = enc.embed("hello world").unwrap();
        let v2 = enc.embed("goodbye moon").unwrap();
        let sim = cosine_similarity(&v1, &v2);
        assert!(sim < 0.9, "different texts should produce different vectors, sim={}", sim);
    }

    #[test]
    fn hash_encoder_empty_input_errors() {
        let enc = SimpleHashEncoder::new(128, 42);
        assert!(enc.embed("").is_err());
        assert!(enc.embed("   ").is_err());
    }

    #[test]
    fn encode_text_produces_unit_10k_vector() {
        let pipeline = make_pipeline();
        let hv = pipeline.encode_text("the quick brown fox").unwrap();
        assert_eq!(hv.len(), 10_000);
        let norm: f32 = hv.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!((norm - 1.0).abs() < 1e-4, "norm was {}", norm);
    }

    #[test]
    fn bind_recovers_similarity() {
        let pipeline = make_pipeline();
        let a = pipeline.encode_text("concept alpha").unwrap();
        let b = pipeline.encode_text("concept beta").unwrap();
        let bound = pipeline.bind(&a, &b);
        // Unbind: bound ⊗ a should be similar to b
        let recovered = pipeline.bind(&bound, &a);
        let sim = cosine_similarity(&recovered, &b);
        // For random-ish unit vectors, binding then unbinding recovers positive similarity
        assert!(sim > 0.1, "expected positive similarity after unbind, got {}", sim);
    }

    #[test]
    fn bundle_has_positive_similarity_to_components() {
        let pipeline = make_pipeline();
        let v1 = pipeline.encode_text("red").unwrap();
        let v2 = pipeline.encode_text("green").unwrap();
        let v3 = pipeline.encode_text("blue").unwrap();
        let bundled = pipeline.bundle(&[v1.clone(), v2.clone(), v3.clone()]);
        assert!(cosine_similarity(&bundled, &v1) > 0.0);
        assert!(cosine_similarity(&bundled, &v2) > 0.0);
        assert!(cosine_similarity(&bundled, &v3) > 0.0);
    }

    #[test]
    fn permute_dissimilar_to_original() {
        let pipeline = make_pipeline();
        let v = pipeline.encode_text("sequence test").unwrap();
        let pv = pipeline.permute(&v, 1);
        let sim = cosine_similarity(&v, &pv);
        assert!(sim < 0.5, "permuted vector should be dissimilar, sim={}", sim);
    }

    // --- Mock encoder that counts calls ---
    use std::sync::atomic::{AtomicUsize, Ordering};
    use std::sync::Arc;

    struct CountingEncoder {
        dim: usize,
        call_count: Arc<AtomicUsize>,
    }

    impl CountingEncoder {
        fn new(dim: usize) -> (Self, Arc<AtomicUsize>) {
            let count = Arc::new(AtomicUsize::new(0));
            (Self { dim, call_count: count.clone() }, count)
        }
    }

    impl TextEncoder for CountingEncoder {
        fn embed(&self, _text: &str) -> Result<Vec<f32>, EncodingError> {
            self.call_count.fetch_add(1, Ordering::SeqCst);
            Ok(vec![1.0; self.dim])
        }
        fn embedding_dim(&self) -> usize { self.dim }
    }

    struct FailingEncoder { dim: usize }
    impl TextEncoder for FailingEncoder {
        fn embed(&self, _text: &str) -> Result<Vec<f32>, EncodingError> {
            Err(EncodingError::Other("always fails".to_string()))
        }
        fn embedding_dim(&self) -> usize { self.dim }
    }

    #[test]
    fn cached_encoder_second_call_uses_cache() {
        let (enc, count) = CountingEncoder::new(64);
        let cached = CachedEncoder::new(enc);
        let _ = cached.embed("hello").unwrap();
        let _ = cached.embed("hello").unwrap();
        assert_eq!(count.load(Ordering::SeqCst), 1);
    }

    #[test]
    fn cached_encoder_different_texts_call_inner() {
        let (enc, count) = CountingEncoder::new(64);
        let cached = CachedEncoder::new(enc);
        let _ = cached.embed("hello").unwrap();
        let _ = cached.embed("world").unwrap();
        assert_eq!(count.load(Ordering::SeqCst), 2);
    }

    #[test]
    fn composite_uses_primary_when_available() {
        let primary = SimpleHashEncoder::new(64, 1);
        let fallback = SimpleHashEncoder::new(64, 2);
        let composite = CompositeEncoder::new(Box::new(primary), Box::new(fallback));
        // Should succeed via primary
        let v = composite.embed("test").unwrap();
        assert_eq!(v.len(), 64);
    }

    #[test]
    fn composite_falls_back_on_primary_error() {
        let primary = FailingEncoder { dim: 64 };
        let fallback = SimpleHashEncoder::new(64, 42);
        let composite = CompositeEncoder::new(Box::new(primary), Box::new(fallback));
        let v = composite.embed("test").unwrap();
        assert_eq!(v.len(), 64);
    }

    #[test]
    fn http_encoder_construction() {
        let enc = HttpEmbeddingEncoder::openai_small("test-key".to_string());
        assert_eq!(enc.embedding_dim(), 1536);
        assert_eq!(enc.model, "text-embedding-3-small");
    }

    #[test]
    fn encode_memory_produces_valid_hypermemory() {
        let pipeline = make_pipeline();
        let mem = pipeline.encode_memory("I met Alice at the park", Utc::now()).unwrap();
        assert_eq!(mem.vector.len(), 10_000);
        assert_eq!(mem.content, "I met Alice at the park");
        assert_eq!(mem.layer_depth, 0);
        assert!(mem.amplitude > 0.0);
        let norm: f32 = mem.vector.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!((norm - 1.0).abs() < 1e-4);
    }
}
